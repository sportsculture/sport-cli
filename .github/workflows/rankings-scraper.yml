name: Scrape OpenRouter Rankings

on:
  schedule:
    # Run daily at 04:37 UTC (randomized minute to be polite)
    - cron: '37 4 * * *'
  workflow_dispatch:
    inputs:
      debug:
        description: 'Enable debug logging'
        required: false
        type: boolean
        default: false

jobs:
  scrape-rankings:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20'
        cache: 'npm'
        cache-dependency-path: scripts/rankings-scraper/package-lock.json
        
    - name: Install dependencies
      working-directory: scripts/rankings-scraper
      run: |
        npm ci || npm install
        
    - name: Run scraper
      working-directory: scripts/rankings-scraper
      run: |
        npm run scrape
      env:
        DEBUG: ${{ inputs.debug }}
        
    - name: Update Gist
      working-directory: scripts/rankings-scraper
      run: |
        npm run update-gist rankings.json
      env:
        GIST_ID: ${{ secrets.GIST_ID }}
        GH_TOKEN: ${{ secrets.GH_TOKEN }}
        
    - name: Upload artifacts (for debugging)
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: rankings-data
        path: scripts/rankings-scraper/rankings.json
        retention-days: 7
        
    - name: Create issue on failure
      if: failure()
      uses: actions/github-script@v7
      with:
        script: |
          const date = new Date().toISOString().split('T')[0];
          const title = `Rankings Scraper Failed - ${date}`;
          
          // Check if issue already exists
          const issues = await github.rest.issues.listForRepo({
            owner: context.repo.owner,
            repo: context.repo.repo,
            labels: 'rankings-scraper',
            state: 'open'
          });
          
          const existingIssue = issues.data.find(i => i.title.includes(date));
          
          if (!existingIssue) {
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: title,
              body: `The rankings scraper workflow failed on ${date}.\n\nWorkflow run: ${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}\n\nThis may indicate that OpenRouter's HTML structure has changed and the scraper needs to be updated.`,
              labels: ['rankings-scraper', 'automated']
            });
          }